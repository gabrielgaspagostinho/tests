# Guia de Integra√ß√£o: M√≥dulo de Infer√™ncia YOLO (ONNX)

Este documento descreve como importar e utilizar o script `inference_harpia.py` como um m√≥dulo em seus pr√≥prios projetos Python.

O m√≥dulo permite realizar infer√™ncias de **Detec√ß√£o de Objetos** e **Classifica√ß√£o** utilizando modelos YOLOv8 exportados para ONNX, sem depender da biblioteca `ultralytics`.

## üì¶ Pr√©-requisitos

Certifique-se de que o arquivo `inference_harpia.py` esteja no mesmo diret√≥rio do seu script principal (ou no `PYTHONPATH`).

Depend√™ncias necess√°rias:
```bash
pip install opencv-python numpy
```

## üöÄ Como Importar

No seu script Python (ex: `main.py` ou `app_robot.py`), importe as classes principais:

```python
# Importa as classes de infer√™ncia
from inference_harpia import YOLODetection, YOLOClass
```

---

## üîç Detec√ß√£o de Objetos (`YOLODetection`)

Use esta classe para identificar objetos, desenhar caixas e obter coordenadas.

### 1. Inicializa√ß√£o

```python
# Caminho do modelo e da imagem
model_path = "models/best_detect.onnx"
img_path = "data/input.jpg"

# Instancia o detector
detector = YOLODetection(
    MODEL_PATH=model_path,
    IMAGE_PATH=img_path,
    INPUT_SIZE=(640, 640),  # Tamanho de entrada do modelo (geralmente 640)
    SCORE_THRESHOLD=0.5,    # Confian√ßa m√≠nima (0.0 a 1.0)
    NMS_THRESHOLD=0.45      # Limiar para remover caixas sobrepostas
)
```

### 2. Obtendo Resultados (`DetectionBox`)

O m√©todo `get_detections()` retorna uma lista de objetos do tipo `DetectionBox`. Cada objeto possui atributos diretos, facilitando o acesso aos dados.

```python
# Obt√©m a lista de objetos detectados
objetos = detector.get_detections()

# Itera sobre os resultados
for obj in objetos:
    print(f"--- Objeto Detectado ---")
    print(f"Classe ID: {obj.class_id}")
    print(f"Score: {obj.score:.2f}")
    
    # Acessando coordenadas e dimens√µes
    print(f"Posi√ß√£o X: {obj.x}, Y: {obj.y}")
    print(f"Largura: {obj.w}, Altura: {obj.h}")
    
    # Exemplo de l√≥gica de decis√£o
    if obj.class_id == 0 and obj.score > 0.8:
        print(">> Alvo priorit√°rio encontrado!")
```

### 3. Visualiza√ß√£o

Para visualizar o resultado em uma janela do OpenCV:

```python
detector.imgshow()
```

---

## üè∑Ô∏è Classifica√ß√£o de Imagens (`YOLOClass`)

Use esta classe para classificar o conte√∫do global de uma imagem (ex: "Dia" vs "Noite", "Defeito" vs "Normal").

### 1. Inicializa√ß√£o

Voc√™ deve fornecer a lista de nomes das classes **na mesma ordem** em que o modelo foi treinado.

```python
# Defini√ß√£o das classes
minhas_classes = ['ilegivel', 'legivel']

# Instancia o classificador
classificador = YOLOClass(
    MODEL_PATH="models/best_classify.onnx",
    IMAGE_PATH="data/manometro.jpg",
    INPUT_SIZE=(640, 640),  # Verifique se seu modelo CLS usa 224 ou 640
    CLASS_NAMES=minhas_classes
)
```

### 2. Obtendo Resultados

O m√©todo `classresult()` retorna um dicion√°rio simples com os dados da predi√ß√£o vencedora.

```python
resultado = classificador.classresult()

# O retorno √© um dicion√°rio: {'id': int, 'score': float, 'name': str}
print(f"Resultado: {resultado['name']}")
print(f"Confian√ßa: {resultado['score']}")
```

### 3. Visualiza√ß√£o

```python
classificador.imgshow()
```

---

## ‚ö†Ô∏è Notas sobre Exporta√ß√£o do Modelo

Para garantir compatibilidade com o OpenCV, exporte seus modelos YOLO (`.pt`) para ONNX utilizando o argumento `opset=12`.

**Comando de exporta√ß√£o(em um terminal com YOLO):**
```bash
yolo export model=best.pt format=onnx opset=12
```
